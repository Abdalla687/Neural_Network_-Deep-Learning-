# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tXt8bcpka2aHJUO0LcuBX2xMBGk_Jgu9
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
#-Generate 1000 sample
n_samples = 1000
#-Range Sample [-1 , 1]
#-Make Metrics 4 dim
X = np.random.uniform(-1, 1, (n_samples, 4))
#-Target Function
x1 , x2 , x3 , x4 = X[:,0] , X[:,1] , X[:,2] , X[:,3]
#-Make Sys Deep Learning
y = np.sin(2 * np.pi * x1) * x2 * x3 * x4 * np.exp(-(x1 + x2 + x3 + x4))
#-Reshape Target , Confirm Shape
y = y.reshape(-1, 1)
#-Make Algorithm Train
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)
#-Make Shape Neurons
model = Sequential()
model.add(Dense(50, activation='sigmoid', input_dim=4))
model.add(Dense(1, activation='linear'))
#-Initialization of a training model (Optimizer => algorithm for update , MSE => Mean_square_error)
model.compile(optimizer=Adam(), loss='mse')
#-Train Model
history = model.fit(X_train, y_train,validation_data=(X_val, y_val),epochs=500,verbose=1)
#-Visualiztion Data
plt.plot(history.history['val_loss'])
plt.xlabel("Epochs")
plt.ylabel("Validation Loss (MSE)")
plt.title("Validation Loss vs Epochs")
plt.grid(True)
plt.savefig("val_loss_curve.png", dpi=300)
plt.show()
#-Find Best epoch
best_epoch = np.argmin(history.history['val_loss'])+1
print(f"Best epoch (lowest validation loss): {best_epoch}")
y_pred = model.predict(X_test)
#-Find Mean_square_error
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
print(f"Root Mean Square Error (RMSE) on test data: {rmse:.4f}")